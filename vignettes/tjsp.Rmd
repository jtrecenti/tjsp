---
title: "TJSP"
author: "Julio Trecenti"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{TJSP}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Download de dados do TJSP

Este documento mostra como baixar os dados do site do TJSP

### Pacotes utilizados

```{r message=FALSE, warning=FALSE}
library(tjsp)
library(esaj)
library(dplyr)
library(stringr)
library(lubridate)
```

### Varas e classes

```{r message=FALSE, warning=FALSE, eval=FALSE}
# baixa lista das varas disponíveis no TJSP
varas <- list_varas_1inst()
# baixa lista das classes processuais
classes <- list_classes_1inst()

# Consideramos apenas comarca de São Paulo
# Apenas varas cíveis ou juizado especial ou itinerante
va <- varas %>%
  filter(str_detect(nm_muni, 'PAULO'),
         str_detect(nm_vara, 'vel|Especial|Iti'),
         !str_detect(nm_vara, 'Crim|Juv|Fam|Faz')) %>%
  with(cod_vara)

# Apenas procedimentos ordinários, sumários, e juizado especial cível
cl <- classes %>%
  filter(str_detect(nm_leaf, 'Procedimento [OSd]'),
         !str_detect(nm_leaf, 'Penal|Criminal'),
         is.na(n0)) %>%
  with(cod_leaf)
```

### Download CJPG

Pesquisa realizada em 23/02/2016.
Datas entre 01/01/2014 e 31/12/2015.
Quebramos as pesquisas por mês para tornar o algoritmo mais rápido, pois
o site do TJSP fica lento ao acessar páginas com índices > 1000.
A pesquisa demorou aproximadamente 8 horas.

```{r eval=FALSE}
d0 <- as.Date('2014-01-01') + months(0:23)
d1 <- as.Date('2014-01-01') + months(1:24) - 1
cjpg_l <- list()
for(i in seq_along(d0)) {
  nm <- format(d0[i], '%Y%m')
  p <- sprintf('data-raw/cjpg/%s', nm)
  suppressWarnings(dir.create(p))
  # Essa é a fç que baixa os dados
  cjpg_l[[nm]] <- cjpg(classes = cl, varas = va, 
                       datas = c(d0[i], d1[i]), path = p)
  cjpg_l[[nm]]$yearmon <- nm
}

# Salvando log dos resultados da cjpg.
cjpg_res <- dplyr::bind_rows(cjpg_l)
saveRDS(cjpg_res, 'data-raw/cjpg_res.rds')
```

### Parse CJPG

A leitura dos arquivos demora aproximadamente uma hora.

```{r eval=FALSE}
# Carregando os nomes dos arquivos a partir das pastas
# O código é um pouco complicado pois estamos pegando
# arquivos de várias pastas.
d_cjpg <- sprintf('data-raw/cjpg', normalizePath(path)) %>% 
  dir(full.names = TRUE) %>% 
  {data_frame(pasta = .)} %>% 
  group_by(pasta) %>% 
  do(data_frame(arq = dir(.$pasta, full.names = TRUE))) %>% 
  ungroup() %>% 
  mutate(pasta = str_extract(pasta, '[0-9]+$')) %>% 
  group_by(pasta, arq) %>% 
  # aqui aplicamos o parser aos arquivos
  do(parse_cjpg_pag(.$arq)) %>% 
  ungroup() %>% 
  distinct(cod_sentenca)

# Salvando d_cjpg.rds
saveRDS(d_cjpg, 'data-raw/d_cjpg.rds')
```

### Download CPO-PG

Pesquisa realizada em 25/02/2016.
Utiliza processamento paralelo para aumentar quantidade de acessos.
A pesquisa demorou aproximadamente dois dias utilizando quatro núcleos.

```{r eval=FALSE}
# Processos que queremos baixar
p <- unique(d_cjpg$n_processo)

dir.create('data-raw/cpo-pg')
d_cpopg_res <- cpo_pg(p, path = 'data-raw/cpo-pg')

# Salvando log dos resultados da cpopg.
saveRDS(d_cpopg_res, 'data-raw/d_cpopg_res.rds')
```

### Parse CPO-PG

A leitura dos arquivos demora aproximadamente doze horas,
utilizando quatro núcleos de processamento.

```{r eval=FALSE}
# Carrega os caminhos dos arquivos baixados
arqs <- dir('data-raw/cpo-pg', full.names = TRUE)
# Utiliza processamento paralelo
d_cpopg <- parse_cpopg(arqs)
# Salvando d_cpopg.rds
saveRDS(d_cpopg, 'data-raw/d_cpopg.rds')
```





